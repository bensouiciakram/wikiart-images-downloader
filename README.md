# WikiArt Minimalism Paintings Scraper

A Scrapy spider that downloads high-quality images of minimalism paintings from WikiArt.org.

## ğŸ“¦ Features
- Automated pagination handling
- Bulk image downloads
- JSON-based data extraction
- Organized image storage
- Auto-throttling for polite crawling

## âš™ï¸ Prerequisites
- Python 3.7+
- Scrapy 2.5+
- Pillow (for image processing)
- chompjs

## ğŸš€ Installation
1. Clone repository:
```bash
git clone https://github.com/yourusername/wikiart-scraper.git
cd wikiart-scraper
```
2. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # Linux/MacOS
venv\Scripts\activate  # Windows
```

3.Install dependencies:
```bash
pip install -r requirements.txt
```
ğŸ“¸ Usage

Run the spider:
```bash
scrapy crawl wikiart
```
Downloaded images will be stored in:

```bash
/images/full/  # Full resolution images
```
ğŸ—‚ Project Structure
```bash
wikiart-scraper/
â”œâ”€â”€ scrapy.cfg
â”œâ”€â”€ images/                  # Downloaded images (created automatically)
â”œâ”€â”€ image_downloader/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ items.py            # Item class definitions
â”‚   â”œâ”€â”€ middlewares.py      # Spider middlewares
â”‚   â”œâ”€â”€ pipelines.py        # Image processing pipeline
â”‚   â”œâ”€â”€ settings.py         # Scrapy configuration
â”‚   â””â”€â”€ spiders/
â”‚       â””â”€â”€ wikiart.py      # Main spider implementation
```

âš™ Configuration (settings.py)

```bash
ITEM_PIPELINES = {'scrapy.pipelines.images.ImagesPipeline': 1}
IMAGES_STORE = 'images'  # Image storage directory
ROBOTSTXT_OBEY = False   # Disable robots.txt compliance
AUTOTHROTTLE_ENABLED = True  # Enable auto-throttling
```
ğŸŒ Spider Details (wikiart.py)

 * Targets: https://www.wikiart.org
 * Pagination: 60 items per page
 * Data extraction:
     * High-resolution image URLs
       






